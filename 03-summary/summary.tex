\documentclass[11pt,letterpaper,oneside]{article}
\usepackage[top=0.5in,left=1in,right=1in,bottom=1in]{geometry}
\usepackage{fancyvrb}
\usepackage{colortbl}
\usepackage{graphicx}
\usepackage{url}

%\usepackage{setspace}
%\doublespacing

\title{summary}
\author{Dejun Qian\\electronseu@gmail.com}

\date{}

\begin{document}
\maketitle

% the problem solved, the approach used, and the results
This paper \cite{bib:Pandita} addresses the problem of automating the verification process of software product based on the Application Programming Interface (API) documents written in natural language.
Software reuse gives software developers the ability to build larger software products with higher quality in shorter time.
The reused software library is usually provided to the developers in the forms of source code or binary executable,
along with the document explaining to how to use itself.
Reading and understanding the document is important, 
or even the only way when no source code is provided,
to correctly use the provided functionalities.
However, the developers are easily overlook some documents,
and misuse some of the functions,
which will leads to potential inconsistency between the software product and the documents.
Many verification tools are developed to detect the inconsistence,
however these tools only accept formal specifications as their input.
They can't understand documents written in natural language.
This paper presents an approach to fill the gap between what is needed by the existing verification tools and what the document can provide.

This paper developed a technique to get the code contract from the library document.
The technique developed in this paper can read the API document,
and output the formal specification in the form of code contract which can be accepted by several verification tools.
Roughly, the technique is composed of two parts: contract sentence selection and code contract generation.
These two parts can be further divided into five steps: parsing, pre-processing, text analysis, post-processing and code contract generation.
In the parsing step, the parser process the API documents and extracts intermediate contents of the method description, 
such as, summary description, argument description, return description, exception description and remark description. 
In the pre-processing step, the pre-processor takes the intermediate content, 
and perform three categories of processing: meta-data augmentation, noun boosting and programming constructs and jargon handling.
These first two steps are critical, as they can improve the results of the third step a lot.
The third step is text analysis.
In this step, this paper developed a text analysis engine framework, 
and adopting an existing POS tagger to annotate POS tags for the input sentences.
After that, they use an NLP technique, called shallow parser to classify the sentences into semantic templates,
based on the lexical tokens generated by the POS tagger.
The shallow parser also generates FOL expressions after it has done the classification.
In the post-processing step, the paper does three types of semantic analysis: removing irrelevant modifiers in predicates, classifying predicates into a semantic class based on domain dictionaries, and augmenting expressions.
In the final step, by using predefined mapping from predicates to code contracts,
the code contract generator translates the FOL into code contracts.

The author wrote a prototype to demonstrate the technique developed,
and did three experiments to evaluate the effectiveness of the approach. 
The experiment results show that this approach gives 92\% precision and 92\% recall towards the contract sentence detection,
and achieves 82\% of accuracy of code contract generation.

\bibliographystyle{acm}
\bibliography{reference}

\end{document}
